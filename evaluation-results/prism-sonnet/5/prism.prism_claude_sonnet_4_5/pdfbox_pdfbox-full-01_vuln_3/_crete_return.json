{
  "project_name": "pdfbox",
  "vulnerability_identifier": "pdfbox_pdfbox-full-01_vuln_3",
  "source_directory": "/home/qqor/crete/.cache/official-afc-pdfbox",
  "llm_usage": {
    "total_cost": 13.783512,
    "prompt_tokens": 3715574,
    "completion_tokens": 175786
  },
  "variant": "sound",
  "diff": "--- a/fontbox/src/main/java/org/apache/fontbox/type1/Type1Parser.java\n+++ b/fontbox/src/main/java/org/apache/fontbox/type1/Type1Parser.java\n@@ -44,6 +44,36 @@\n     private static final int EEXEC_KEY = 55665;\n     private static final int CHARSTRING_KEY = 4330;\n \n+    /**\n+     * Maximum dictionary size to prevent timeout.\n+     */\n+    private static final int MAX_DICT_SIZE = 10000;\n+\n+    /**\n+     * Maximum array size to prevent timeout.\n+     */\n+    private static final int MAX_ARRAY_SIZE = 10000;\n+\n+    /**\n+     * Maximum iterations when searching for tokens.\n+     */\n+    private static final int MAX_TOKEN_SEARCH_ITERATIONS = 100000;\n+\n+    /**\n+     * Maximum nesting depth for procedures and arrays.\n+     */\n+    private static final int MAX_NESTING_DEPTH = 100;\n+\n+    /**\n+     * Maximum number of subroutines.\n+     */\n+    private static final int MAX_SUBRS = 10000;\n+\n+    /**\n+     * Maximum number of charstrings.\n+     */\n+    private static final int MAX_CHARSTRINGS = 10000;\n+\n     // state\n     private Type1Lexer lexer;\n     private Type1Font font;\n@@ -107,6 +137,10 @@\n \n         // font dict\n         int length = read(Token.INTEGER).intValue();\n+        if (length < 0 || length > MAX_DICT_SIZE)\n+        {\n+            throw new DamagedFontException(\"Invalid dictionary size: \" + length);\n+        }\n         read(Token.NAME, \"dict\");\n         // found in some TeX fonts\n         readMaybe(Token.NAME, \"dup\");\n@@ -214,18 +248,28 @@\n             // 0 1 255 {1 index exch /.notdef put } for\n             // we have to check \"readonly\" and \"def\" too\n             // as some fonts don't provide any dup-values, see PDFBOX-2134\n+            int iterations = 0;\n             while (!(lexer.peekKind(Token.NAME)\n                     && (lexer.peekToken().getText().equals(\"dup\")\n                             || lexer.peekToken().getText().equals(\"readonly\")\n                             || lexer.peekToken().getText().equals(\"def\"))))\n             {\n+                if (++iterations > MAX_TOKEN_SEARCH_ITERATIONS)\n+                {\n+                    throw new DamagedFontException(\"Token search exceeded maximum iterations\");\n+                }\n                 lexer.nextToken();\n             }\n             \n             Map<Integer, String> codeToName = new HashMap<>();\n+            int entryCount = 0;\n             while (lexer.peekKind(Token.NAME) &&\n                     lexer.peekToken().getText().equals(\"dup\"))\n             {\n+                if (++entryCount > MAX_DICT_SIZE)\n+                {\n+                    throw new DamagedFontException(\"Encoding entries exceed maximum: \" + MAX_DICT_SIZE);\n+                }\n                 read(Token.NAME, \"dup\");\n                 int code = read(Token.INTEGER).intValue();\n                 String name = read(Token.LITERAL).getText();\n@@ -318,6 +362,10 @@\n         Map<String, List<Token>> dict = new HashMap<>();\n \n         int length = read(Token.INTEGER).intValue();\n+        if (length < 0 || length > MAX_DICT_SIZE)\n+        {\n+            throw new DamagedFontException(\"Invalid dictionary size: \" + length);\n+        }\n         read(Token.NAME, \"dict\");\n         readMaybe(Token.NAME, \"dup\");\n \n@@ -392,8 +440,13 @@\n         if (token.getKind() == Token.START_ARRAY)\n         {\n             int openArray = 1;\n+            int iterations = 0;\n             while (true)\n             {\n+                if (++iterations > MAX_TOKEN_SEARCH_ITERATIONS)\n+                {\n+                    throw new DamagedFontException(\"Array parsing exceeded maximum iterations\");\n+                }\n                 if (lexer.peekToken() == null)\n                 {\n                     return value;\n@@ -401,6 +454,10 @@\n                 if (lexer.peekKind(Token.START_ARRAY))\n                 {\n                     openArray++;\n+                    if (openArray > MAX_NESTING_DEPTH)\n+                    {\n+                        throw new DamagedFontException(\"Array nesting exceeds maximum depth: \" + MAX_NESTING_DEPTH);\n+                    }\n                 }\n \n                 token = lexer.nextToken();\n@@ -471,8 +528,13 @@\n         List<Token> value = new ArrayList<>();\n \n         int openProc = 1;\n+        int iterations = 0;\n         while (true)\n         {\n+            if (++iterations > MAX_TOKEN_SEARCH_ITERATIONS)\n+            {\n+                throw new DamagedFontException(\"Procedure parsing exceeded maximum iterations\");\n+            }\n             if (lexer.peekToken() == null)\n             {\n                 throw new IOException(\"Malformed procedure: missing token\");\n@@ -481,6 +543,10 @@\n             if (lexer.peekKind(Token.START_PROC))\n             {\n                 openProc++;\n+                if (openProc > MAX_NESTING_DEPTH)\n+                {\n+                    throw new DamagedFontException(\"Procedure nesting exceeds maximum depth: \" + MAX_NESTING_DEPTH);\n+                }\n             }\n \n             Token token = lexer.nextToken();\n@@ -510,8 +576,13 @@\n     private void readProcVoid() throws IOException\n     {\n         int openProc = 1;\n+        int iterations = 0;\n         while (true)\n         {\n+            if (++iterations > MAX_TOKEN_SEARCH_ITERATIONS)\n+            {\n+                throw new DamagedFontException(\"Procedure parsing exceeded maximum iterations\");\n+            }\n             if (lexer.peekToken() == null)\n             {\n                 throw new IOException(\"Malformed procedure: missing token\");\n@@ -519,6 +590,10 @@\n             if (lexer.peekKind(Token.START_PROC))\n             {\n                 openProc++;\n+                if (openProc > MAX_NESTING_DEPTH)\n+                {\n+                    throw new DamagedFontException(\"Procedure nesting exceeds maximum depth: \" + MAX_NESTING_DEPTH);\n+                }\n             }\n \n             Token token = lexer.nextToken();\n@@ -554,8 +629,13 @@\n \n         // find /Private dict\n         Token peekToken = lexer.peekToken();\n+        int iterations = 0;\n         while (peekToken != null && !\"Private\".equals(peekToken.getText()))\n         {\n+            if (++iterations > MAX_TOKEN_SEARCH_ITERATIONS)\n+            {\n+                throw new DamagedFontException(\"Token search for /Private exceeded maximum iterations\");\n+            }\n             // for a more thorough validation, the presence of \"begin\" before Private\n             // determines how code before and following charstrings should look\n             // it is not currently checked anyway\n",
  "stdout": "",
  "stderr": ""
}