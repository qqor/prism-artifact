{
  "project_name": "pdfbox",
  "vulnerability_identifier": "pdfbox_pdfbox-full-01_vuln_3",
  "source_directory": "/tasks_new/pdfbox_pdfbox-full-01/official-afc-pdfbox",
  "llm_usage": {
    "total_cost": 0.49332030000000004,
    "prompt_tokens": 281225,
    "completion_tokens": 41812
  },
  "variant": "sound",
  "diff": "--- a/fontbox/src/main/java/org/apache/fontbox/type1/Type1Parser.java\n+++ b/fontbox/src/main/java/org/apache/fontbox/type1/Type1Parser.java\n@@ -44,6 +44,11 @@\n     private static final int EEXEC_KEY = 55665;\n     private static final int CHARSTRING_KEY = 4330;\n \n+    // limits to prevent unbounded loops in Type 1 parsing\n+    private static final int MAX_DICT_ENTRIES    = 10_000;\n+    private static final int MAX_ENCODING_TOKENS = 10_000;\n+    private static final int MAX_DUP_ENTRIES     = 1_000;\n+    private static final int MAX_PROCVOID_TOKENS = 100_000;\n     // state\n     private Type1Lexer lexer;\n     private Type1Font font;\n@@ -107,6 +112,9 @@\n \n         // font dict\n         int length = read(Token.INTEGER).intValue();\n+        if (length < 0 || length > MAX_DICT_ENTRIES) {\n+            throw new IOException(\"Invalid dictionary length: \" + length);\n+        }\n         read(Token.NAME, \"dict\");\n         // found in some TeX fonts\n         readMaybe(Token.NAME, \"dup\");\n@@ -214,18 +222,23 @@\n             // 0 1 255 {1 index exch /.notdef put } for\n             // we have to check \"readonly\" and \"def\" too\n             // as some fonts don't provide any dup-values, see PDFBOX-2134\n+            int encodingTokenCount = 0;\n             while (!(lexer.peekKind(Token.NAME)\n-                    && (lexer.peekToken().getText().equals(\"dup\")\n-                            || lexer.peekToken().getText().equals(\"readonly\")\n-                            || lexer.peekToken().getText().equals(\"def\"))))\n-            {\n+                    && (\"dup\".equals(lexer.peekToken().getText())\n+                        || \"readonly\".equals(lexer.peekToken().getText())\n+                        || \"def\".equals(lexer.peekToken().getText())))) {\n+                if (lexer.peekToken() == null || ++encodingTokenCount > MAX_ENCODING_TOKENS) {\n+                    throw new IOException(\"Malformed encoding: too many tokens\");\n+                }\n                 lexer.nextToken();\n             }\n             \n             Map<Integer, String> codeToName = new HashMap<>();\n-            while (lexer.peekKind(Token.NAME) &&\n-                    lexer.peekToken().getText().equals(\"dup\"))\n-            {\n+            int dupCount = 0;\n+            while (lexer.peekKind(Token.NAME) && \"dup\".equals(lexer.peekToken().getText())) {\n+                if (++dupCount > MAX_DUP_ENTRIES) {\n+                    throw new IOException(\"Too many dup entries: \" + dupCount);\n+                }\n                 read(Token.NAME, \"dup\");\n                 int code = read(Token.INTEGER).intValue();\n                 String name = read(Token.LITERAL).getText();\n@@ -510,14 +523,13 @@\n     private void readProcVoid() throws IOException\n     {\n         int openProc = 1;\n-        while (true)\n-        {\n-            if (lexer.peekToken() == null)\n-            {\n-                throw new IOException(\"Malformed procedure: missing token\");\n-            }\n-            if (lexer.peekKind(Token.START_PROC))\n-            {\n+        int procTokenCount = 0;\n+        while (true) {\n+            Token next = lexer.peekToken();\n+            if (next == null || ++procTokenCount > MAX_PROCVOID_TOKENS) {\n+                throw new IOException(\"Malformed or too long procedure\");\n+            }\n+            if (lexer.peekKind(Token.START_PROC)) {\n                 openProc++;\n             }\n \n",
  "stdout": "",
  "stderr": ""
}